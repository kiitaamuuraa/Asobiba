{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PTReinfrocementLearning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOgsy7F+Qf5cv3u7ecNbwNP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiitaamuuraa/Asobiba/blob/main/PTReinfrocementLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKrVSsHf0Jp1"
      },
      "source": [
        "## [REINFORCEMENT LEARNING (DQN) TUTORIAL](https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC0yoyaE0j9u"
      },
      "source": [
        "## installation some requirements  \n",
        "This is not from the original tutorial article. Some requirement for the Colab env are added."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWX1Hb0QsLip",
        "outputId": "16ffcb4b-3d71-4a65-eca1-ae6caddf1122"
      },
      "source": [
        "# https://stackoverflow.com/questions/53472940/nameerror-name-base-is-not-defined-openai-gym\n",
        "!apt-get install -y xvfb x11-utils\n",
        "!pip install gym[box2d]==0.17.* pyvirtualdisplay==0.2.* PyOpenGL==3.1.* PyOpenGL-accelerate==3.1.*"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libxxf86dga1\n",
            "Suggested packages:\n",
            "  mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  libxxf86dga1 x11-utils xvfb\n",
            "0 upgraded, 3 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 994 kB of archives.\n",
            "After this operation, 2,981 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.9 [784 kB]\n",
            "Fetched 994 kB in 1s (774 kB/s)\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "(Reading database ... 160837 files and directories currently installed.)\n",
            "Preparing to unpack .../libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../x11-utils_7.7+3build1_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+3build1) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.9_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n",
            "Setting up x11-utils (7.7+3build1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Requirement already satisfied: gym[box2d]==0.17.* in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Collecting pyvirtualdisplay==0.2.*\n",
            "  Downloading PyVirtualDisplay-0.2.5-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: PyOpenGL==3.1.* in /usr/local/lib/python3.7/dist-packages (3.1.5)\n",
            "Collecting PyOpenGL-accelerate==3.1.*\n",
            "  Downloading PyOpenGL-accelerate-3.1.5.tar.gz (538 kB)\n",
            "\u001b[K     |████████████████████████████████| 538 kB 8.0 MB/s \n",
            "\u001b[?25hCollecting EasyProcess\n",
            "  Downloading EasyProcess-0.3-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.19.5)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.17.*) (1.4.1)\n",
            "Collecting box2d-py~=2.3.5\n",
            "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 41.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[box2d]==0.17.*) (0.16.0)\n",
            "Building wheels for collected packages: PyOpenGL-accelerate\n",
            "  Building wheel for PyOpenGL-accelerate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyOpenGL-accelerate: filename=PyOpenGL_accelerate-3.1.5-cp37-cp37m-linux_x86_64.whl size=1599505 sha256=83484d45a31d14453a4da39e159e5fd5a6ffd6de092bfd16d73052c988de65a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/f5/6f/169afb3f2d476c5e807f8515b3c9bc9b819c3962316aa804eb\n",
            "Successfully built PyOpenGL-accelerate\n",
            "Installing collected packages: EasyProcess, box2d-py, pyvirtualdisplay, PyOpenGL-accelerate\n",
            "Successfully installed EasyProcess-0.3 PyOpenGL-accelerate-3.1.5 box2d-py-2.3.8 pyvirtualdisplay-0.2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GIwN6ZV8Fwe"
      },
      "source": [
        "import pyvirtualdisplay\n",
        "\n",
        "\n",
        "_display = pyvirtualdisplay.Display(visible=False,  # use False with Xvfb\n",
        "                                    size=(1400, 900))\n",
        "_ = _display.start()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXkRmAPUsXgb"
      },
      "source": [
        "import gym\n",
        "import math \n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple, deque\n",
        "from itertools import count\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg-pJNqItBHi"
      },
      "source": [
        "env = gym.make('CartPole-v0').unwrapped"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yucHe48stJym"
      },
      "source": [
        "is_ipython = 'inline' in matplotlib.get_backend()\n",
        "if is_ipython:\n",
        "    from IPython import display\n",
        "plt.ion()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oarGpKItKid",
        "outputId": "1c7f8eb1-b4b5-49ef-e1e1-091942eeac79"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn4GVQC4txlP"
      },
      "source": [
        "Transition = namedtuple('Transition',\n",
        "                        ('state', 'action', 'next_state', 'reward'))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJg66Y0Aty43"
      },
      "source": [
        "class ReplayMemory(object):\n",
        "    def __init__(self, capacity):\n",
        "        self.memory = deque([], maxlen=capacity)\n",
        "\n",
        "    def push(self, *args):\n",
        "        self.memory.append(Transition(*args))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFdOafaWvSKw"
      },
      "source": [
        "class DQN(nn.Module):\n",
        "    def __init__(self, h, w, outputs):\n",
        "        super(DQN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
        "        self.bn3 = nn.BatchNorm2d(32)\n",
        "\n",
        "        # 畳み込み後のサイズの計算でFC層に変換するときに使う\n",
        "        def conv2d_size_out(size, kernel_size=5, stride=2):\n",
        "            return (size - (kernel_size - 1) - 1) // stride + 1\n",
        "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
        "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
        "        linear_input_size = convw * convh * 32\n",
        "        self.head = nn.Linear(linear_input_size, outputs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(device)\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        return self.head(x.view(x.size(0), -1))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHUgGZUEz41f",
        "outputId": "f40b7892-7d07-4d3e-eda8-f5a1086868dc"
      },
      "source": [
        "resize = T.Compose([T.ToPILImage(), T.Resize(40, interpolation=Image.CUBIC), T.ToTensor()])\n",
        "\n",
        "def get_cart_location(screen_width):\n",
        "    world_width = env.x_threshold * 2\n",
        "    scale = screen_width / world_width\n",
        "    return int(env.state[0] * scale + screen_width / 2.0)\n",
        "\n",
        "def get_screen():\n",
        "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
        "    _, screen_height, screen_width = screen.shape\n",
        "    screen = screen[:, int(screen_height*0.4): int(screen_height*0.8)]\n",
        "    view_width = int(screen_width * 0.6)\n",
        "    cart_location = get_cart_location(screen_width)\n",
        "    if cart_location < view_width // 2:\n",
        "        slice_range = slice(view_width)\n",
        "    elif cart_location > (screen_width - view_width // 2):\n",
        "        slice_range = slice(-view_width, None)\n",
        "    else:\n",
        "        slice_range = slice(cart_location - view_width // 2, cart_location + view_width // 2)\n",
        "    screen = screen[:, :, slice_range]\n",
        "    screen = np.ascontiguousarray(screen, dtype=np.float32)\n",
        "    screen = torch.from_numpy(screen)\n",
        "    return resize(screen).unsqueeze(0)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:281: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYPp5h_J58ig"
      },
      "source": [
        "screen = env.render(mode='rgb_array')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "qlgYRvVp4nxN",
        "outputId": "7cdbcb14-fdbf-4fc6-a7b3-fd54a9598b81"
      },
      "source": [
        "env.reset()\n",
        "plt.figure()\n",
        "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(), interpolation='none')\n",
        "plt.title('Example extracted screen')\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olBIsJKHyGYT"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "GAMMA = 0.999\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 200\n",
        "TARGET_UPDATE = 10\n",
        "\n",
        "init_screen = get_screen()\n",
        "_, _, screen_height, screen_width = init_screen.shape\n",
        "\n",
        "n_actions = env.action_space.n\n",
        "policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
        "target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()\n",
        "\n",
        "optimizer = optim.RMSprop(policy_net.parameters())\n",
        "memory = ReplayMemory(10000)\n",
        "\n",
        "steps_done = 0"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNpx2pshzsAP"
      },
      "source": [
        "def select_action(state):\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END) * math.exp(-1.0 * steps_done / EPS_DECAY)\n",
        "    steps_done += 1\n",
        "\n",
        "    if sample > eps_threshold:\n",
        "        with torch.no_grad():\n",
        "            return policy_net(state).max(1)[1].view(1, 1)\n",
        "\n",
        "    else:\n",
        "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK8DZOKGzyX3"
      },
      "source": [
        "episode_durations =[]\n",
        "def plot_durations():\n",
        "    plt.figure(2)\n",
        "    plt.clf()\n",
        "    duration_t = torch.tensor(episode_durations, dtype=torch.float)\n",
        "    plt.title('Training...')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Duration')\n",
        "    plt.plot(duration_t.numpy())\n",
        "\n",
        "    plt.pause(0.001)\n",
        "    if is_ipython:\n",
        "        display.clear_output(wait=True)\n",
        "        display.display(plt.gcf())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETUrefZxAyTQ"
      },
      "source": [
        "def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "    batch = Transition(*zip(*transitions))\n",
        "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, batch.next_state)), device=device, dtype=torch.bool)\n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
        "    state_batch = torch.cat(batch.state)\n",
        "    action_batch = torch.cat(batch.action)\n",
        "    reward_batch = torch.cat(batch.reward)\n",
        "\n",
        "    state_action_value = policy_net(state_batch).gather(1, action_batch)\n",
        "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
        "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "\n",
        "    criterion = nn.SmoothL1Loss()\n",
        "    loss = criterion(state_action_value, expected_state_action_values.unsqueeze(1))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    for param in policy_net.parameters():\n",
        "        param.grad.data.clamp_(-1, 1)\n",
        "    optimizer.step()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ha7t8j8sA2XX",
        "outputId": "eb0ba2ff-fd49-42cf-d359-5f72f09fe4d8"
      },
      "source": [
        "num_episodes = 50\n",
        "for i_episode in range(num_episodes):\n",
        "    env.reset()\n",
        "    last_screen = get_screen()\n",
        "    current_screen = get_screen()\n",
        "    state = current_screen - last_screen\n",
        "    for t in count():\n",
        "        action = select_action(state)\n",
        "        _, reward, done, _ = env.step(action.item())\n",
        "        reward = torch.tensor([reward], device=device)\n",
        "\n",
        "        last_screen = current_screen\n",
        "        current_screen = get_screen()\n",
        "        if not done:\n",
        "            next_state = current_screen - last_screen\n",
        "        else:\n",
        "            next_state = None\n",
        "        memory.push(state, action, next_state, reward)\n",
        "        state = next_state\n",
        "\n",
        "        optimize_model()\n",
        "        if done:\n",
        "            episode_durations.append(t + 1)\n",
        "            plot_durations()\n",
        "            time.sleep(2)\n",
        "            break\n",
        "    if i_episode % TARGET_UPDATE == 0:\n",
        "        target_net.load_state_dict(policy_net.state_dict())\n",
        "    \n",
        "\n",
        "print('Complete')\n",
        "env.render()\n",
        "env.close()\n",
        "plt.ioff()\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-4acb9536b12f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mepisode_durations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mplot_durations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi_episode\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mTARGET_UPDATE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UyR_Mdj87Y4"
      },
      "source": [
        "import time"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZNV_FQOA5D4"
      },
      "source": [
        "scr = get_screen().squeeze().numpy()\n",
        "print(scr.shape)\n",
        "\n",
        "scr = scr.transpose(1, 2, 0)\n",
        "scr.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KcZ_1Ea6tIh"
      },
      "source": [
        "scr = Image.fromarray(scr)\n",
        "display.display(scr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcD2Kzyy7G-S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}