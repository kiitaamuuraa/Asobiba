{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MyFirstLXMERT.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO4Ch8p+U1pwhcXRnqt9MG9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiitaamuuraa/Asobiba/blob/main/MyFirstLXMERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJxhQmyP0W8H"
      },
      "source": [
        "# LXMERT × object Refferal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnkUr0Z80ShP",
        "outputId": "d62d0c70-336e-488a-bba3-c7ba439166f2"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/d8/5144b0712f7f82229a8da5983a8fbb8d30cec5fbd5f8d12ffe1854dcea67/transformers-4.4.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 5.7MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 36.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 51.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=c39f941a21a7d0c1ac51522bd689a70b34652194697ba6759670949bc228c511\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKKzwCsM0l-W"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.utils.data import Dataset, Dataset\r\n",
        "from torch.utils.tensorboard import SummaryWriter\r\n",
        "\r\n",
        "from transformers import LxmertTokenizer, LxmertModel"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1tGovmvQM-p"
      },
      "source": [
        "## トークナイザとモデルの定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jA6UGyM20zuX",
        "outputId": "28e33085-9850-464d-d4d7-4b6ceb328d76"
      },
      "source": [
        "tokenizer = LxmertTokenizer.from_pretrained('unc-nlp/lxmert-base-uncased')\r\n",
        "model = LxmertModel.from_pretrained('unc-nlp/lxmert-base-uncased')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.2955, 0.3331, 0.6159, 0.5383],\n",
              "         [0.7964, 0.1018, 0.9522, 0.5114],\n",
              "         [0.9440, 0.6369, 0.7073, 0.3295]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NWW1LwrQmls"
      },
      "source": [
        "## 入力（ダミー）の定義  \r\n",
        "**注意:** 画像に関する情報を定義しないと、モデルはエラーを返す"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMravCUm4EJA",
        "outputId": "7bc38f28-d272-41a6-c382-faa3eb10faa9"
      },
      "source": [
        "sent = ['President Joe Biden sat down with ABC News George Stephanopoulos for a wide-ranging interview Tuesday in which he said his message to migrants was to not come to the border and that New York Gov.',\r\n",
        "         'Andrew Cuomo should resign if allegations he committed sexual harassment are confirmed.',\r\n",
        "        'And he said it would be \"tough\" to withdraw all American troops from Afghanistan by May 1, a deadline set out in a deal former President Donald Trump\\'s administration made with the Taliban.']\r\n",
        "\r\n",
        "inputs = tokenizer(sent, return_tensors=\"pt\", padding=True, truncation=True)\r\n",
        "print(inputs['input_ids'].shape)\r\n",
        "\r\n",
        "# ダミーの画像特徴量を作成\r\n",
        "# batch x num_images x dim\r\n",
        "visual_feats = torch.randn([3, 64, 2048])\r\n",
        "inputs['visual_feats'] = visual_feats\r\n",
        "\r\n",
        "# ダミーの画像特徴量の座標作成\r\n",
        "# batch x num_images x dim\r\n",
        "visual_pos = torch.rand([3, 64, 4])\r\n",
        "inputs['visual_pos'] = visual_pos"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 43])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zumct8dcQR2D"
      },
      "source": [
        "## "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA9BA_cP1AwF"
      },
      "source": [
        "outputs = model(**inputs)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh1KD-AJ1Njm",
        "outputId": "8d815eb7-4b9e-4f65-e321-d753606137cd"
      },
      "source": [
        "# サイズ確認\r\n",
        "for k in outputs.keys():\r\n",
        "    print(k, outputs[k].shape)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "language_output torch.Size([3, 43, 768])\n",
            "vision_output torch.Size([3, 64, 768])\n",
            "pooled_output torch.Size([3, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sb5V3LEPJy7"
      },
      "source": [
        "## ターゲットの画像のImage Feature から16個をランダムサンプル"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn3mrSdQ238e",
        "outputId": "b95b2459-6204-4de7-86cf-5a97d3940438"
      },
      "source": [
        "import random\r\n",
        "\r\n",
        "def get_idx(num_sample=16, all_options=63):\r\n",
        "    idx = list()\r\n",
        "    while len(idx) < num_sample:\r\n",
        "        id = random.randint(0, all_options)\r\n",
        "        if id not in idx:\r\n",
        "            idx.append(id)\r\n",
        "    return torch.tensor(idx)\r\n",
        "\r\n",
        "l = list()\r\n",
        "for i, b in enumerate(visual_feats):\r\n",
        "    l.append(b[get_idx()])\r\n",
        "    random_samples = torch.stack(l, dim=0)\r\n",
        "\r\n",
        "random_samples.shape"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 16, 2048])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkiISrGGO-Xz"
      },
      "source": [
        "## ランダムにラベルを作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFqDVbXxG-8z"
      },
      "source": [
        "import numpy as np\r\n",
        "labels = np.array([random.randint(0,15) for i in range(3)])"
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOYh4TYNVbWU"
      },
      "source": [
        "## 内積を取る"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh2718MRamks"
      },
      "source": [
        "fc = torch.nn.Linear(768, 2048)"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5YE4l5eW_Qc",
        "outputId": "0d14e9cf-a0e7-48c5-f522-c375163378d2"
      },
      "source": [
        "cross_modal_features = outputs['pooled_output'] # クロスモーダルの特徴量\r\n",
        "print(cross_modal_features.shape)\r\n",
        "\r\n",
        "# 元画像の特徴量にサイズを合わせる\r\n",
        "cross_modal_features = fc(cross_modal_features)\r\n",
        "\r\n",
        "# bmm用にリピート\r\n",
        "cross_modal_features = cross_modal_features.unsqueeze(dim=1)\r\n",
        "print(cross_modal_features.shape)"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 768])\n",
            "torch.Size([3, 1, 2048])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2TLMcpaWENJ"
      },
      "source": [
        "batch_cos_sim = torch.bmm(cross_modal_features, random_samples.permute(0,2,1)).squeeze() # b(3) x target(16)"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52VpERYSb4en"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\r\n",
        "criterion(batch_cos_sim, torch.tensor(labels))"
      ],
      "execution_count": 210,
      "outputs": []
    }
  ]
}